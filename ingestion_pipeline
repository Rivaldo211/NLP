#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import logging
import sys
import yaml
from os.path import split

from dotenv import load_dotenv
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from datetime import datetime

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_groq import ChatGroq

# Logging Configuration
formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(funcName)-30s %(message)s')
fh = logging.FileHandler("main.log")
sh = logging.StreamHandler()
fh.setLevel(logging.DEBUG)
sh.setLevel(logging.INFO)
fh.setFormatter(formatter)
sh.setFormatter(formatter)


# load Api key
load_dotenv()

# Paths
with open("config.yaml", "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

INDEX_PATH = config["paths"]["index_path"]
DATABASE_PATH = config["paths"]["database_path"]

def embed_documents(doc_path: str):
    if os.path.exists(doc_path):
        loader = DirectoryLoader(doc_path, glob="*.txt", loader_cls=TextLoader, loader_kwargs={"encoding": "utf-8"})
        docs = loader.load()
        logging.info("DATABASE Loaded ")

        # split
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(docs)
        return splits
    else:
        return logging.error("Path Error")

def init_retriever():
    try:
        # Prepare Documents
        splits = embed_documents(DATABASE_PATH)

        # Generate embeddings
        embeddings = OpenAIEmbeddings()

        # load or create FAISS-Base
        if os.path.exists(INDEX_PATH):
            logging.info("Loading existing FAISS database...")
            vectordb = FAISS.load_local(
                folder_path=INDEX_PATH,
                embeddings=embeddings,
                allow_dangerous_deserialization=True
            )
        else:
            logging.info("Creating a new FAISS database...")
            vectordb = FAISS.from_documents(splits, embeddings)
            vectordb.save_local(folder_path=INDEX_PATH)

        # Return retriever
        return vectordb.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 4, "fetch_k": 8}
        )

    except Exception as e:
        logging.error(f"Error initializing the retriever : {str(e)}")
        raise

# save Metadaten
def _info(embedding_model: str, chunk_size=1000, chunk_overlap=200):
    metadaten_docs= []
    splits = embed_documents(DATABASE_PATH)
    now = datetime.now().isoformat()

    for doc in splits:
        new_metadata = doc.metadata.copy()
        new_metadata.update({
            "embedding_model": embedding_model,
            "created_at": now,
            "chunk_size": chunk_size,
            "chunk_overlap": chunk_overlap,
        })
        metadaten_docs.append(type(doc)(
            page_content=doc.page_content,
            metadata=new_metadata
        ))
    return metadaten_docs


SYSTEM_PROMPT_TEMPLATE = """
        You are a cybersecurity and CTI assistant for students and analysts.
        Use ONLY the provided CONTEXT to answer the question.
        context:  {context}
        question: {question} 
        The user will enter a 'question', which can be : a text or a keyword with question mark at the end
        or a text or a keyword without question mark at the end.
        your job:
        Interpret the input as a technical question, even if it doesn’t have a question mark.
        If the input is too short or ambiguous (e.g. “api”), start with a brief general definition relevant to cybersecurity/CTI.
        If the information is not present in the CONTEXT, respond exactly with 'I don't know, please make sure that a question mark at the end and try again or another questions'.
        Keep answers concise and, always say 'Hello' at the beginning of the answer.
        in next line always say 'thanks for asking' at the end of the answer
"""


class LLM:

    def __init__(self):
        self.prompt = ChatPromptTemplate.from_template(SYSTEM_PROMPT_TEMPLATE)
        logging.info("Initialisation du retriever...")
        self.retriever = init_retriever()
        logging.info("Vector base is ready.")

    def get_llm(self):
        return ChatGroq(model="openai/gpt-oss-120b", temperature=0.8)

    def answer(self, query: str) -> str:

        def format_docs(docs):
            return "\n".join(doc.page_content for doc in docs)

        chain =   ({"question": RunnablePassthrough(),"context": self.retriever |format_docs}
                   |self.prompt |self.get_llm() |StrOutputParser())
        return chain.invoke(query)

def main():
    print("Welcome to a CTI Assistant\n Enter 'quit' or 'exit' to exit to the assistant.")

    while True:
        query = input("\nQuestion: ")
        if query.lower() in ("quit", "exit"):
            print("Goodbye!")
            sys.exit(0)

        try:
            llm = LLM()
            response = llm.answer(query)
            print(response)
        except Exception as ex:
            print(f"Error to generate answer : {str(ex)}")

if __name__ == "__main__":
    print("Configuration loaded...")
    main()
