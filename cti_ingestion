#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import logging
#initialise le yaml file
import yaml
from os.path import split

from dotenv import load_dotenv
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from datetime import datetime

# Logging Configuration
formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(funcName)-30s %(message)s')
fh = logging.FileHandler("main.log")
sh = logging.StreamHandler()
fh.setLevel(logging.DEBUG)
sh.setLevel(logging.INFO)
fh.setFormatter(formatter)
sh.setFormatter(formatter)

# load Api key
load_dotenv()

# Paths
INDEX_PATH = "./storage/faiss_db"
DATABASE_PATH = "C:/Users/Rivaldo/Documents/ATIS/orkl.eu-2025-09-25-txtonly-subset/"

def embed_documents(doc_path: str):
    if os.path.exists(doc_path):
        loader = DirectoryLoader(doc_path, glob="*.txt", loader_cls=TextLoader, loader_kwargs={"encoding": "utf-8"})
        docs = loader.load()
        logging.info("Loading DATABASE")

        # split
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(docs)
        return splits
    else:
        return logging.error("Path Error")

def init_retriever():
    try:
        # Prepare Documents
        splits = embed_documents(DATABASE_PATH)

        # Generate embeddings
        embeddings = OpenAIEmbeddings()

        # load or create FAISS-Base
        if os.path.exists(INDEX_PATH):
            logging.info("Loading existing FAISS database...")
            vectordb = FAISS.load_local(
                folder_path=INDEX_PATH,
                embeddings=embeddings,
                allow_dangerous_deserialization=True
            )
        else:
            logging.info("Creating a new FAISS database...")
            vectordb = FAISS.from_documents(splits, embeddings)
            vectordb.save_local(folder_path=INDEX_PATH)

        # Return retriever
        return vectordb.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 4, "fetch_k": 8}
        )

    except Exception as e:
        logging.error(f"Error initializing the retriever : {str(e)}")
        raise

# save Metadaten
def _info(embedding_model: str, chunk_size=1000, chunk_overlap=200):
    metadaten_docs= []
    splits = embed_documents(DATABASE_PATH)
    now = datetime.now().isoformat()

    for doc in splits:
        new_metadata = doc.metadata.copy()
        new_metadata.update({
            "embedding_model": embedding_model,
            "created_at": now,
            "chunk_size": chunk_size,
            "chunk_overlap": chunk_overlap,
        })
        metadaten_docs.append(type(doc)(
            page_content=doc.page_content,
            metadata=new_metadata
        ))
    return metadaten_docs

if __name__ == "__main__":
    logging.info("Initialisation du retriever...")
    retriever = init_retriever()
    logging.info("Vector base is ready.")
